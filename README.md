Safespace - Mental Health Companion Setup Guide
ğŸš€ Quick Start

Your Next.js mental health companion app is ready to go! Follow these steps:
1. Install Dependencies

Make sure you have all dependencies installed:
bash

npm install

2. Run the Development Server
bash

npm run dev

Open http://localhost:3000 in your browser.
ğŸ“ Files Created

All files have been created according to your directory structure:
Core Files

    âœ… app/page.tsx - Main application page
    âœ… app/layout.tsx - Root layout
    âœ… app/globals.css - All styling (exact copy from your CSS)

Components

    âœ… app/components/Sidebar.tsx - Navigation sidebar
    âœ… app/components/ChatSection.tsx - Chat interface
    âœ… app/components/JournalSection.tsx - Journal with modal
    âœ… app/components/MoodSection.tsx - Mood tracker with chart
    âœ… app/components/InsightsSection.tsx - Statistics and insights

Library Files

    âœ… lib/types.ts - TypeScript type definitions
    âœ… lib/api.ts - Data management functions

Hooks

    âœ… hooks/useAppData.ts - Custom hook for app state

API Routes (Placeholder for future server-side storage)

    âœ… app/api/journal/route.ts
    âœ… app/api/mood/route.ts
    âœ… app/api/insights/route.ts

ğŸ¨ Features Implemented
âœ… Fully Working Features:

    Theme Toggle - Dark/Light mode with localStorage persistence
    Chat Interface - Message display and input (ready for LLM integration)
    Journal System - Write entries with mood selection, filter by date
    Mood Tracker - Log moods with notes, visual weekly chart
    Insights Dashboard - Stats, streaks, and mood trigger analysis
    Responsive Design - Works on mobile, tablet, and desktop
    Data Persistence - All data saved to localStorage (works offline)

ğŸ¤– Integrating Your Local LLM

Currently, the chat uses a placeholder response. To integrate your local LLM:
Option 1: Replace the placeholder in app/page.tsx

Find this code around line 47:
typescript

// Simulate bot response (replace this with your local LLM later)
setTimeout(() => {
  const botMessage: Message = {
    id: `msg_${Date.now()}`,
    content: `I hear you. Thank you for sharing that with me...`,
    isUser: false,
    timestamp: new Date(),
  };
  addNewMessage(botMessage);
}, 1000);

Replace with your LLM call:
typescript

// Example with local LLM
const response = await fetch('http://localhost:11434/api/generate', {
  method: 'POST',
  body: JSON.stringify({
    model: 'your-model',
    prompt: content,
    stream: false
  })
});

const data = await response.json();
const botMessage: Message = {
  id: `msg_${Date.now()}`,
  content: data.response,
  isUser: false,
  timestamp: new Date(),
};
addNewMessage(botMessage);

Option 2: Create a dedicated API route

Create app/api/chat/route.ts:
typescript

export async function POST(request: Request) {
  const { message } = await request.json();
  
  // Call your local LLM here
  const response = await yourLLMFunction(message);
  
  return NextResponse.json({ response });
}

Then update the handleSendMessage function to call this endpoint.
ğŸ“Š Data Storage

Currently uses localStorage for client-side storage. This means:

    âœ… Works completely offline
    âœ… No server needed
    âœ… Data persists between sessions
    âš ï¸ Data is device-specific (doesn't sync across devices)

If you want server-side storage later, the API routes are ready as placeholders.
ğŸ¯ Project Structure

app/
â”œâ”€â”€ api/              # API routes (placeholder)
â”œâ”€â”€ components/       # React components
â”œâ”€â”€ globals.css       # All styling
â”œâ”€â”€ layout.tsx        # Root layout
â””â”€â”€ page.tsx          # Main page

hooks/
â””â”€â”€ useAppData.ts     # Data management hook

lib/
â”œâ”€â”€ api.ts           # localStorage functions
â””â”€â”€ types.ts         # TypeScript types

ğŸ”§ Configuration Files

Your existing config files should work fine:

    next.config.ts
    tsconfig.json
    tailwind.config.js
    postcss.config.mjs

ğŸ¨ Styling

All styling is in app/globals.css with CSS custom properties for theming. No Tailwind classes are used in the components - pure CSS as per your original design.
ğŸ“± Responsive Breakpoints

    Mobile: < 480px
    Tablet: < 768px
    Desktop: > 768px

ğŸ” Privacy Note

Since this is an offline-first app using localStorage:

    All data stays on the user's device
    Nothing is sent to any server (until you add LLM integration)
    Perfect for sensitive mental health data

ğŸš¨ Troubleshooting
Module resolution errors?

Make sure your tsconfig.json has:
json

{
  "compilerOptions": {
    "paths": {
      "@/*": ["./*"]
    }
  }
}

CSS not loading?

The CSS is in app/globals.css and should be imported in layout.tsx.
Data not persisting?

Check browser console for localStorage errors. Some browsers block localStorage in private/incognito mode.
ğŸ‰ You're Ready!

Everything is set up and working. Just run npm run dev and start using your mental health companion app!

When you're ready to add your local LLM, simply replace the placeholder in the handleSendMessage function.
# safespace_ai
